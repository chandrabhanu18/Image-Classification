{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63829a6c",
   "metadata": {},
   "source": [
    "# Transfer Learning Image Classification (PyTorch)\n",
    "Comprehensive, reproducible workflow: data prep, augmentation, baseline CNN, ResNet50 transfer learning (two-phase), metrics, confusion matrix, Grad-CAM, and saving artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637fddf",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "- Build high-performance classifier on custom dataset via transfer learning (ResNet50).\n",
    "- Two-phase training: feature extraction (frozen backbone) then fine-tuning (top layers unfrozen, low LR).\n",
    "- Baseline CNN for comparison.\n",
    "- Evaluation: accuracy, precision, recall, F1, confusion matrix.\n",
    "- Interpretability: Grad-CAM heatmaps.\n",
    "- Reproducibility: deterministic seeds, clear configs, checkpoints.\n",
    "\n",
    "> Set your dataset root before running: `DATA_ROOT = \"./data/your_dataset\"` with `train/`, `val/`, `test/` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Environment\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from utils.data import build_transforms, create_dataloaders\n",
    "from utils.models import build_baseline, build_resnet50, unfreeze_top_layers, param_groups\n",
    "from utils.gradcam import GradCAM, overlay_heatmap\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_root: str = \"./data/your_dataset\"  # update to your dataset path\n",
    "    image_size: int = 224\n",
    "    batch_size: int = 32\n",
    "    num_workers: int = 2\n",
    "    num_epochs_head: int = 8\n",
    "    num_epochs_ft: int = 12\n",
    "    lr_head: float = 3e-4\n",
    "    lr_backbone: float = 1e-5\n",
    "    weight_decay: float = 1e-4\n",
    "    early_stop_patience: int = 5\n",
    "    grad_accum_steps: int = 1\n",
    "    trainable_layers_ft: int = 10\n",
    "    baseline_epochs: int = 10\n",
    "    output_dir: str = \"./models\"\n",
    "    viz_dir: str = \"./visualizations\"\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "Path(cfg.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(cfg.viz_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading & Visualization Helpers\n",
    "loaders, sizes, class_names = create_dataloaders(\n",
    "    data_root=cfg.data_root,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    image_size=cfg.image_size,\n",
    ")\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Sizes:\", sizes)\n",
    "\n",
    "# Quick sanity check: visualize a training batch\n",
    "def show_batch(loader: DataLoader, title: str = \"Train Batch\"):\n",
    "    images, labels = next(iter(loader))\n",
    "    grid = make_grid(images[:16], nrow=4, normalize=True, padding=2)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(title)\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to visualize\n",
    "# show_batch(loaders[\"train\"], \"Train examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea388f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Utilities\n",
    "\n",
    "def accuracy_from_logits(logits, targets):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scheduler=None, grad_accum=1):\n",
    "    model.train()\n",
    "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
    "    optimizer.zero_grad()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y) / grad_accum\n",
    "        loss.backward()\n",
    "        if (step + 1) % grad_accum == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        acc = accuracy_from_logits(logits, y)\n",
    "        total_loss += loss.item() * grad_accum\n",
    "        total_acc += acc\n",
    "        n_batches += 1\n",
    "    if scheduler:\n",
    "        scheduler.step(total_loss / n_batches)\n",
    "    return total_loss / n_batches, total_acc / n_batches\n",
    "\n",
    "\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, n_batches = 0.0, 0.0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            acc = accuracy_from_logits(logits, y)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            n_batches += 1\n",
    "            all_preds.append(torch.argmax(logits, dim=1).cpu())\n",
    "            all_targets.append(y.cpu())\n",
    "    preds = torch.cat(all_preds)\n",
    "    targets = torch.cat(all_targets)\n",
    "    return total_loss / n_batches, total_acc / n_batches, preds, targets\n",
    "\n",
    "\n",
    "def plot_curves(history, title: str, path: str):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[\"train_acc\"], label=\"train\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=200)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121229fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN (from scratch)\n",
    "baseline = build_baseline(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(baseline.parameters(), lr=1e-3, weight_decay=cfg.weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "history_base = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "best_val = 0.0\n",
    "best_path = os.path.join(cfg.output_dir, \"baseline_best.pth\")\n",
    "\n",
    "for epoch in range(cfg.baseline_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(baseline, loaders[\"train\"], criterion, optimizer)\n",
    "    val_loss, val_acc, _, _ = eval_model(baseline, loaders[\"val\"], criterion)\n",
    "    scheduler.step(val_loss)\n",
    "    history_base[\"train_loss\"].append(train_loss)\n",
    "    history_base[\"val_loss\"].append(val_loss)\n",
    "    history_base[\"train_acc\"].append(train_acc)\n",
    "    history_base[\"val_acc\"].append(val_acc)\n",
    "    print(f\"[Baseline] Epoch {epoch+1}/{cfg.baseline_epochs} - train_acc: {train_acc:.3f}, val_acc: {val_acc:.3f}\")\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        torch.save({\"model_state\": baseline.state_dict(), \"class_names\": class_names}, best_path)\n",
    "\n",
    "plot_curves(history_base, \"Baseline CNN\", os.path.join(cfg.viz_dir, \"baseline_curves.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3069302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning: ResNet50 Setup\n",
    "resnet = build_resnet50(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(resnet.fc.parameters(), lr=cfg.lr_head, weight_decay=cfg.weight_decay)\n",
    "\n",
    "history_head = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "best_val = 0.0\n",
    "head_ckpt = os.path.join(cfg.output_dir, \"resnet50_head.pth\")\n",
    "\n",
    "print(\"Phase 1: Feature extraction (backbone frozen)\")\n",
    "for epoch in range(cfg.num_epochs_head):\n",
    "    train_loss, train_acc = train_one_epoch(resnet, loaders[\"train\"], criterion, optimizer, grad_accum=cfg.grad_accum_steps)\n",
    "    val_loss, val_acc, _, _ = eval_model(resnet, loaders[\"val\"], criterion)\n",
    "    history_head[\"train_loss\"].append(train_loss)\n",
    "    history_head[\"val_loss\"].append(val_loss)\n",
    "    history_head[\"train_acc\"].append(train_acc)\n",
    "    history_head[\"val_acc\"].append(val_acc)\n",
    "    print(f\"[Head] Epoch {epoch+1}/{cfg.num_epochs_head} - train_acc: {train_acc:.3f}, val_acc: {val_acc:.3f}\")\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        torch.save({\"model_state\": resnet.state_dict(), \"class_names\": class_names}, head_ckpt)\n",
    "\n",
    "plot_curves(history_head, \"ResNet50 - Head Training\", os.path.join(cfg.viz_dir, \"resnet_head_curves.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eeeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning: Fine-Tuning Top Layers\n",
    "# Unfreeze top layers\n",
    "unfreeze_top_layers(resnet, trainable_layers=cfg.trainable_layers_ft)\n",
    "\n",
    "# Differential learning rates: lower for backbone, higher for head\n",
    "optimizer_ft = AdamW(param_groups(resnet, base_lr=cfg.lr_backbone, head_lr=cfg.lr_head), weight_decay=cfg.weight_decay)\n",
    "scheduler_ft = ReduceLROnPlateau(optimizer_ft, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "history_ft = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "best_val_ft = 0.0\n",
    "ft_ckpt = os.path.join(cfg.output_dir, \"resnet50_finetuned.pth\")\n",
    "patience = cfg.early_stop_patience\n",
    "wait = 0\n",
    "\n",
    "print(\"Phase 2: Fine-tuning (top layers unfrozen)\")\n",
    "for epoch in range(cfg.num_epochs_ft):\n",
    "    train_loss, train_acc = train_one_epoch(resnet, loaders[\"train\"], criterion, optimizer_ft, grad_accum=cfg.grad_accum_steps)\n",
    "    val_loss, val_acc, _, _ = eval_model(resnet, loaders[\"val\"], criterion)\n",
    "    scheduler_ft.step(val_loss)\n",
    "\n",
    "    history_ft[\"train_loss\"].append(train_loss)\n",
    "    history_ft[\"val_loss\"].append(val_loss)\n",
    "    history_ft[\"train_acc\"].append(train_acc)\n",
    "    history_ft[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"[FT] Epoch {epoch+1}/{cfg.num_epochs_ft} - train_acc: {train_acc:.3f}, val_acc: {val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_ft:\n",
    "        best_val_ft = val_acc\n",
    "        torch.save({\"model_state\": resnet.state_dict(), \"class_names\": class_names}, ft_ckpt)\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "plot_curves(history_ft, \"ResNet50 - Fine-tuning\", os.path.join(cfg.viz_dir, \"resnet_ft_curves.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on Test Set (Baseline vs Transfer)\n",
    "\n",
    "def evaluate_and_report(model, loader, name: str):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss, acc, preds, targets = eval_model(model, loader, criterion)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, preds, average=\"weighted\")\n",
    "    print(f\"{name} - loss: {loss:.4f}, acc: {acc:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}\")\n",
    "    print(classification_report(targets, preds, target_names=class_names))\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(cfg.viz_dir, f\"cm_{name}.png\"), dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "# Load best checkpoints and evaluate\n",
    "baseline_ckpt = torch.load(os.path.join(cfg.output_dir, \"baseline_best.pth\"), map_location=device)\n",
    "baseline.load_state_dict(baseline_ckpt[\"model_state\"])\n",
    "\n",
    "evaluate_and_report(baseline.to(device), loaders[\"test\"], name=\"baseline\")\n",
    "\n",
    "resnet_ckpt = torch.load(os.path.join(cfg.output_dir, \"resnet50_finetuned.pth\"), map_location=device)\n",
    "resnet.load_state_dict(resnet_ckpt[\"model_state\"])\n",
    "\n",
    "evaluate_and_report(resnet.to(device), loaders[\"test\"], name=\"resnet50_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b515e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM Visualization\n",
    "# Use the last conv block of ResNet50 (layer4[-1]) as target\n",
    "cam_extractor = GradCAM(resnet, target_layer=resnet.layer4[-1])\n",
    "\n",
    "# Select a few test images\n",
    "def gradcam_on_samples(loader: DataLoader, class_names, k: int = 3):\n",
    "    resnet.eval()\n",
    "    images, labels = next(iter(loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    for i in range(min(k, images.size(0))):\n",
    "        img = images[i].unsqueeze(0)\n",
    "        label = labels[i].item()\n",
    "        with torch.no_grad():\n",
    "            logits = resnet(img)\n",
    "            pred = logits.argmax(dim=1).item()\n",
    "        heatmap = cam_extractor(img, class_idx=pred)\n",
    "        base_img, overlay = overlay_heatmap(img.squeeze(0), heatmap)\n",
    "\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"True: {class_names[label]}\\nPred: {class_names[pred]}\")\n",
    "        plt.imshow(base_img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Grad-CAM\")\n",
    "        plt.imshow(overlay)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        out_path = os.path.join(cfg.viz_dir, f\"gradcam_{i}.png\")\n",
    "        plt.savefig(out_path, dpi=200)\n",
    "        plt.show()\n",
    "\n",
    "# Uncomment to run Grad-CAM\n",
    "# gradcam_on_samples(loaders[\"test\"], class_names, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13178c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Artifacts\n",
    "# Save fine-tuned model state and config metadata\n",
    "final_artifact = {\n",
    "    \"model_state\": resnet.state_dict(),\n",
    "    \"class_names\": class_names,\n",
    "    \"config\": asdict(cfg),\n",
    "}\n",
    "final_path = os.path.join(cfg.output_dir, \"resnet50_final.pth\")\n",
    "torch.save(final_artifact, final_path)\n",
    "print(\"Saved final model to\", final_path)\n",
    "\n",
    "# Save histories for reproducibility\n",
    "with open(os.path.join(cfg.output_dir, \"history_baseline.json\"), \"w\") as f:\n",
    "    json.dump(history_base, f, indent=2)\n",
    "with open(os.path.join(cfg.output_dir, \"history_head.json\"), \"w\") as f:\n",
    "    json.dump(history_head, f, indent=2)\n",
    "with open(os.path.join(cfg.output_dir, \"history_ft.json\"), \"w\") as f:\n",
    "    json.dump(history_ft, f, indent=2)\n",
    "print(\"Saved training histories.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
